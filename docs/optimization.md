# Optimization

This section focuses on the theory and behavior of optimization algorithms used in machine learning, with an emphasis on convergence, complexity, and the interplay between dynamics and structure.

## Surveys and Tutorials
+ **A Survey of Optimization Methods for Training DL Models: Theoretical Perspective on Convergence and Generalization** *(arXiv, 2025)* [[paper]](https://arxiv.org/abs/2501.14458)  
  Jing Wang, Anna Choromanska

## Gradient Descent
+ **Minimax Optimal Convergence of Gradient Descent in Logistic Regression via Large and Adaptive Stepsizes** *(arXiv, 2025)* [[paper]](https://arxiv.org/abs/2504.04105)  
  Ruiqi Zhang, Jingfeng Wu, Licong Lin, Peter L. Bartlett


## Stochastic Optimization

+ **SGD: General Analysis and Improved Rates** *(ICML, 2019)* [[paper]](https://arxiv.org/abs/1901.09401)  
  Robert Mansel Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev, Egor Shulgin, Peter Richtarik

## Optimization for Deep Learning

(See also [Deep Learning Theory](learning-theory.md#deep-learning-theory))